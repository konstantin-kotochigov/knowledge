{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Графы  vs сети\n",
    "\n",
    "Графы (Graphs) и сети (Networks) - термины во многом синонимичные. Когда исследуются абстрактные математические свойства, чаще используется термин граф. Когда изучаются прикладные аспекты реальных систем, чаще говорят о сетевом анализе. \n",
    "\n",
    "В теории графов (Graph theory) граф = множество вершин (vertex), соединенных ребрами (edge)\n",
    "\n",
    "В сетевом анализе (Network science) сеть = множество узлов (node), между которыми заданы связи/отношения (link/relation)\n",
    "\n",
    "На этом занятии будем испольовать обе терминологии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Примеры сетей\n",
    "В реальном мире есть множество примеров, которые могут быть описаны сетями.\n",
    "- social network - сети людей, между которым существуют различные отношения (отношения знакомства, фолловинга и прочее)\n",
    "- knowledge graph - граф информации (позволяет выполнять слоные реляционные запросы)\n",
    "- web graph - мнжество страниц во всемирной сети, обхединенных соотношением\n",
    "- reference graph - множество документов, в , отношение - указание в качестве источника\n",
    "- computation graph - граф вычислений, отношение - использование результата вычисления в качестве входа нового вычисления\n",
    "- food network - питание биологических видов (кто кого ест)\n",
    "- molecule graph - разработка новых молекулярных соединений\n",
    "- state graph - математическое описание динамических систем, из одного осстояния можно перейти в другое, если есть между ними есть связь (задачи навигации)\n",
    "\n",
    "#### Области практического применения\n",
    "1. Дескприптивная аналитика и теоретические изыскания\n",
    "  - выявление и описание особенностей структуры изучаемой сети\n",
    "  - определение наиболее значимых узлов\n",
    "  - определение наиболее значимых групп узлов\n",
    "  - изучение распростарнения Fake News\n",
    "2. Задачи оптимизации\n",
    "  - поиск оптимального пути на графе\n",
    "3. Machine Learning и прогнозирование\n",
    "  - использование информации о связности объектов в задачах классификации\n",
    "  - link prediction - рекомендации новых свзей\n",
    "  - определение близости товаров для рекомендаций\n",
    "  - расследование мошеннических схем (изучается как социальный граф, так и граф юридических лиц)\n",
    "  - dimension reduction, любая выборка может быть представлена в виде графа, а его спектральное разложение дает сокращенное описание\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовая типология графов\n",
    "\n",
    "<span style=\"color:blue\">Undirected</span> (ненаправленные) графы - такие графы, у которых ребра не имеют направления, то есть две вершины X и Y могут быть соединены только одним ребром e(X,Y)\n",
    "\n",
    "<span style=\"color:blue\">Directed</span> (направленные) графы - графы, у которых ребро имеет направление, вершины X и Y могут быть соединены и как e(X,Y), и как e(Y,X)\n",
    "\n",
    "<span style=\"color:blue\">Weighted</span> (взвешенные) графы - такие графы, у которых с каждым ребром ассоциирован некоторый вес, характеризующий силу связи\n",
    "\n",
    "<span style=\"color:blue\">Bipartite</span> (двудольные) графы - графы, у которых каждая вершина относится к одному из двух типов и каждое ребро соединяет вершины разного типа\n",
    "\n",
    "<img src=\"img/bipartite.gif\" width=350>\n",
    "\n",
    "Примеры двудольных графов (S1, S2 - вершины, R - отношения)\n",
    "- S1 = картинки, S2 = коллекции картинок, R = картинка включена в коллекцию\n",
    "- S1 = научные журналы, S2 = авторы, R = автор опубликовал статью в журнале\n",
    "- S1 = продукты, S2 = пользователи, R = пользователь купил продукт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные способы описания графов\n",
    "\n",
    "**<span style=\"color:blue\">Adjacency matrix</span>** (матрица смежности) - квадратная матрица, в которой строки и столбцы обозначают вершину графа, а элемент матрицы характеризует наличие (1) или отсутствие (0) ребра\n",
    "\n",
    "<img src=\"img/adjacency.jpg\" width=500>\n",
    "\n",
    "Матрица смежности может быть аналогично задана и для направленных, и для взвешенных графов. \n",
    "\n",
    "Если граф направленный, матрица перестает быть симметричной:\n",
    "\n",
    "<img src=\"img/adjacency_directed.png\" width=500>\n",
    "\n",
    "**<span style=\"color:blue\">Incidence matrix</span>** - прямоугольная матрица, у которой по строкам отложены вершины, по столбцам - ребра. Каждый элемент матрицы описывает наличие (1) или отсутствие (0) ребра, соединяющего данные вершины\n",
    "\n",
    "<img src=\"img/incidence.png\" width=500>\n",
    "\n",
    "Аналогичная матрица может быть построена для направленного графа. В этом случае каждый элемент матрицы может принимать не два значения (0:нет ребра, 1:есть ребро) а три (-1: входящее ребро, 0: нет ребра, 1: исходящее ребро).\n",
    "\n",
    "<img src=\"img/incidence_directed.jpg\" width=500>\n",
    "\n",
    "<span style=\"color:blue\">Node Degree</span> (степень вершины) - число ребер, проходящих через данную вершину (инцидентных данной вершине)\n",
    "\n",
    "Для направленных графов также выделяют:\n",
    "- in-degree, количество входящих ребер\n",
    "- out-degree, количество исходящих ребер\n",
    "\n",
    "in-degree легко посчитать, как поколоночную сумму матрицы смежности\n",
    "\n",
    "out-degree считается, как построчная сумма матрицы смежности\n",
    "\n",
    "**<span style=\"color:blue\">Degree matrix</span>** - диагональная матрица, элементы которой описывают степень вершины\n",
    "\n",
    "<img src=\"img/degree.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality\n",
    "\n",
    "Одна из важных задач сетевого анализа - определить \"вес\" каждой вершины и выделить наиболее \"значимые\" с той или иной позиции. <span style=\"color:blue\"> Centrality</span> - показатель “важности” вершины в графе. Так как “важность” - довольно абстрактный термин, существует несколько различных вариантов этого показателя:\n",
    "\n",
    "### Distance centralities\n",
    "\n",
    "<span style=\"color:blue\">Degree centrality</span>, или насколько тесно данная вершина взаимодействует с другими вершинами\n",
    "\n",
    "Считается просто как степень вершины\n",
    "\n",
    "<span style=\"color:blue\">Closeness centrality</span>, или насколько близка данная вершина к ”центру” графа\n",
    "\n",
    "Считается, как среднее расстояние до других вершин\n",
    "\n",
    "<span style=\"color:blue\">Betweenness centrality</span>, или насколько данную вершину можно назвать связующим элементом сети\n",
    "\n",
    "Счиатется как доля кратчайших путей между всеми парами вершин графа, которые проходят через данную вершину\n",
    "\n",
    "### Spectral centralities\n",
    "\n",
    "<span style=\"color:blue\">Eigrnvalue centrality</span> - рассчитывается рекурсивно на основании соседей. Классическая имплементация - это алшгоритм PageRank.\n",
    "\n",
    "\n",
    "Идея простая: значимость узла складывается из значимости соседей:\n",
    "$$C_{eig}(x)=\\frac{1}{\\lambda}\\sum_{y \\ \\rightarrow x}C_{eig}(y)$$\n",
    "\n",
    "Оказывается, если k раз повторить описаный выше шаг распространения значимости, то оно сойдется к некоторому стабильному значению и его можно будет расписать в матричной форме:\n",
    "$$Ax=\\lambda x$$\n",
    "\n",
    "Решением этого уравнения являются собственные вектора матрицы A, поэтому метод называется eigenvalue centrality.\n",
    "\n",
    "<span style=\"color:blue\">Katz centrality</span> - считает количество путей, которыми можно прийти из ноды в остальные ноды за 1..k шагов.\n",
    "<img src=\"img/centrality_katz.png\" width=200>\n",
    "где:\n",
    "\n",
    "- $\\alpha$ - параметр затухания (attenuation factor). Реализует логику, что длинные пути в расчете метрики должны учитываться с меньшим весом, чем короткие\n",
    "$(0,\\frac{1}{\\lambda})$, иначе подсчет Katz centrality не сойдется.\n",
    "\n",
    "\n",
    "- $A^k$ - k-ая степень матрицы смежности, каждый элемент которой показывает число путей длины k, которые ведут из i в j (можно ходить взад-вперед). Если прийти в ноду за k шагов нельзя, то там 0 будет.\n",
    "\n",
    "\n",
    "- $\\beta$ - параметр, который задает, насколько большим будет разброс между центральностями\n",
    "\n",
    "\n",
    "### Пример\n",
    "\n",
    "На графе ниже отмечены наиболее значимые ноды с позиции различных метрик центральности\n",
    "\n",
    "<img src=\"img/centrality.png\">\n",
    "\n",
    "Можно, конечно весьма условно, провести аналогию с классическими статистиками: средним, медианой и модой. Closeness centrality является аналогом среднего значения, betweenness centrality - медианы, а Degree centality является модой. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank\n",
    "\n",
    "PageRank - описанная в 1998 году основателем Google Сергеем Брином метрика, которая оценивает \"важность\" страницы в интернете. В то время метрика имела ключевое значение при определении порядка вывода в результатах поиска - наиболее \"значимые\" сайты должны были идти первыми. Метрика использовалась в google поиске вплоть до 2016 года.\n",
    "\n",
    "Как оценить важность страницы?\n",
    "Просто количество ссылок на страницу - плохой показатель, можно легко насоздавать фейковых страниц. Должно учитываться еще и качество этих страниц.\n",
    "\n",
    "#### Принцип расчета\n",
    "1. pagerank страницы суммируется из весов всех ссылающихся на нее соседних страниц\n",
    "2. вес каждой такой ссылки считается как единица деленная на число исходящих ссылок. То есть, можно сказать, важность страницы делится в равной доле между всеми исходящими из нее ссылками.\n",
    "\n",
    "В виде формулы это выглядит так:\n",
    "\n",
    "\n",
    "Важно понимать, что pagerank конечно не единственный показатель, влияющий на порядок поисковой выдачи (в реальности их сотни или даже тысячи). Качество страницы может определяться множеством способов.\n",
    "\n",
    "Эта же формула может быть выведена через Random Walk, так как блуждание происходит по Макрковской матрице случайных переходов, и получаемое в итоге стационарное распределение и есть вектор весов вершин\n",
    "\n",
    "\n",
    "Эта же формула может быть выведена, как собственный вектор матрицы смежности веб-графа, так как именно собственный вектор матрицы при уможении на него этой матрицы сохраняет направление. Поэтому eigenvalue centrality и есть PageRank\n",
    "\n",
    "#### Проблемы\n",
    "В таком виде у алгоритм:\n",
    "1. может зависнуть в цикле\n",
    "2. может не быть исзходящих ссылок\n",
    "\n",
    "Чтобы побороть первую - в алгоритм добавляется вероятностная телепортация (с веротяностью 10% random walk стратует из другой вершины) \n",
    "Чтобы обойти вторую - для страниц без исходящих ссылок добавляют равновероятный переход по всем страницам\n",
    "\n",
    "#### Сходимость\n",
    "В оригинальной версии (300млн страниц) было достаточно ~ 50 шагов power iteration для сходимости\n",
    "\n",
    "#### Разновидности алгоритма\n",
    "разновидности алгоритма - personalized pagerank и random walk with restart\n",
    "\n",
    "#### PageRank для рекомендаций\n",
    "неочевидный пример применения - оценка близости товаров/пользователей в двудольном графе товарных предпочтений в задаче рекомендаций\n",
    "\n",
    "\n",
    "#### альтернативные метрики:\n",
    "У Яндекса тематический индекс цитирования ТИЦ, который в 2018 году был заменен ИКС (индексом качества сайта)\n",
    "HITS (hubs )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HITS\n",
    "\n",
    "HITS - это альтернативная (и менее распространенная) метрика.\n",
    "\n",
    "Главные отличия от PageRank\n",
    "1. считается не на всем множестве страниц, а только на подмоножестве страниц, релевантных некоторому запросу Q. \n",
    "    \n",
    "    То есть этот механизм работает только в привязке к конектрному запросу\n",
    "\n",
    "\n",
    "2. вычисляется не одна, а сразу две характеристики: authority-score (информационность) и hub-score (хабовость)\n",
    "\n",
    "Использовалась в ask.com\n",
    "\n",
    "#### Ключевая идея\n",
    "В сети интернет преобладают страницы двух типов - \n",
    "- hubs (хабы) - страницы, основная цель которых перенаправлять на другие (более информативные) страницы \n",
    "\n",
    "    то есть если Out-degree >> In-degree\n",
    "\n",
    "\n",
    "- authorities (авторитеты) - страницы, основная цель которых предоставлять полезную информацию\n",
    "\n",
    "    то есть если In-degree >> Out-degree\n",
    "\n",
    "<img src=\"img/hits1.jpg\" width=300>\n",
    "\n",
    "Кстати, как посчитать in-degree и out-degree матрицы?\n",
    "out-degree = A * r, где A = adjacency и r = единичный вектор \n",
    "in-degree = AT * r, где A = adjacency и r = единичный вектор\n",
    "Если r - не единичный вектор, а текущее распредение некоторой массы в графе, умножив на него матрицу A, можно получить следущий шаг итерации в модели переноса потока.\n",
    "\n",
    "#### Алгоритм\n",
    "1. сборка графа\n",
    "    - сначала задаем root set (корневой набор) страниц, релевантных анализируемому запросу Q\n",
    "    - формируем base set (базовый набор) - добавляем к набору страницы, ссылающиеся на этот root set\n",
    "    <img src=\"img/hits0.jpg\" width=300>\n",
    "2. для каждой страницы будем итеративно обновлять 2 показателя: \n",
    "    - A = authority-score \n",
    "    - H = hub-score\n",
    "3. инициалзиация\n",
    "    - веса A и H по всем страницам ставятся равными единице\n",
    "4. шаг алгоритма\n",
    "    - новый A(v) страницы суммируется из H-весов ссылающихся на нее страниц\n",
    "    - новый H(v) страницы суммируется из A-весов страниц, на которую страница ссылается\n",
    "    - вектора весов A и H нормализуются => получается распределение авторитетности и  по вершинам графа\n",
    "    <img src=\"img/hits2.jpg\" width=300>\n",
    "\n",
    "На первой итерации алгоритма показатели будут равны соотвественно:\n",
    "- A(v) = In(v) \n",
    "- H(v) = Out(v)\n",
    "\n",
    "Через некоторое количество итераций, вектора весов сходятся к реальному значению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering coefficient\n",
    "\n",
    "Коэффициент кластеризации - показатель связности графа.\n",
    "\n",
    "**<span style=\"color:blue\">Local clustering coefficient</span>** - показатель кластеризации для отдельно взятой вершины\n",
    "\n",
    "Рассмотрим окрестность вершины (neighborhood) и выведем все связи между вершинами этой окретсности. \n",
    "У нас может получиться либо звезда (star graph), либо полный граф (complete graph), либо что-то посередине. \n",
    "\n",
    "Если получается звезда, вершина слабо связана с соседями. Если полный граф, то наоборот вершина приндалжит некому сообществу.\n",
    "\n",
    "<img src=\"img/clustering.jpg\">\n",
    "\n",
    "Коэффициент кластеризации считается как отношение числа ребер, соединяющих соседей от числа всех возможных ребер. В полном графе у нас $\\frac{k(k-1)}{2}$ ребер. Соответственно, коэффициент считается как\n",
    "$$\\frac{N_v}{k(k-1)/2}$$\n",
    "\n",
    "**<span style=\"color:blue\">Average clustering coefficient</span>** - показатель кластеризации уровня графа, получается усреднением локальных коэффициентов\n",
    "\n",
    "**<span style=\"color:blue\">Global clustering coeffiient</span>** - еще один показатель кластеризации уровня графа, который считается иначе. \n",
    "\n",
    "Любой граф может быть представлен в виде комбинации троек вершин (<span style=\"color:blue\">triplets</span>). Каждая тройка называется <span style=\"color:blue\">открытой</span>, если в ней 2 ребра или <span style=\"color:blue\">закрытой</span>, если в тройке 3 ребра. Глобальный коэффициент считается как отношение закрытых троек к числу любых троек.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivity\n",
    "\n",
    "Связность графа (Connectivity) или, что то же самое, cohesion, считается как минмиальное количество вершин которое достаточно удалить из графа, что он перестад быть связным. Это тможнет быть важно для определения наличия узких мест и подсчета общей устойчивости графа. Удаление вершин называется node cut, ребер -  edge cut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если не указывается иного, расстоянием между вершинами графа является геодезическое расстояние, то есть минимальное количество ребер которые необходимо пройти чтобы попасть ихз вершины A в B.\n",
    "\n",
    "Во многих алгоритмах уменьшения размерности (задача dimension reduction) для корректного сжатия сложных спиралевидных многообразий стандартное евклидово расстояние заменяется на геодезическое, посчитанное на построенном путем соединения ближайших соседей графе выборки.\n",
    "\n",
    "Граф называется термином small world, если среднее расстояние меньше log(N).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assortiveness\n",
    "\n",
    "Assortiveness - насколько вершины в графе имеют тенденцию соединяться с вершинами с той же степенью. Считается просто как корреляция (Пирсона) между степенями двух вершин, составляющих ребро.\n",
    "\n",
    "В общем случае, измеряться может не только степень вершины, но и любое свойство (пол/возраст/марка машины). Термин применяется во многих доменах и означает предпочтение себе подобных, еще называется гомофилия (в противовес гомофобии)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Embeddings\n",
    "\n",
    "### Adjacency-based\n",
    "\n",
    "Идея: ищем такие вложения вершин, чтобы их скалярное произведение было максимально близко матрице смежности графа\n",
    "\n",
    "### Multi-hop\n",
    "\n",
    "### Random Walk\n",
    "\n",
    "Идея: для каждой вершины графа u мы генерируем множество случайных блужданий заданной длины, стартующих в данной вершине. В итоге для каждой вершины v мы можем оценить вероятность P(v|u). Далее мы ищем такие вложения вершин, чтобы скалярное произведение максимизировало эту веротяность\n",
    "\n",
    "### Convolutional Graph Networks\n",
    "\n",
    "1. выбираем глубину окрестности вершины\n",
    "2. на дальнем слое на вход подаются значения вершин\n",
    "3. на всех промежуточных слоях выполняется агрегация входов в одно значение (аналогия с пулингом с классических сверточных сетях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knowled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Classification\n",
    "\n",
    "Постановка: есть информация по некоторым нодам, к какому классу (label) эти ноды отноятся. Нужно экстраполировать эту классификацию на остальные ноды. Например, в социальной сети есть подвыборка любителей шоколада (про них точно знаем) и мы хотим предсказать по всем остальным пользователям насколько веротяно что они тоже .\n",
    "\n",
    "#### Local Classifier\n",
    "Класс ноды восстанавливается на основе параметров. То есть это стандартная постановка задача классификации, просто наблюдениями являются узлы графа.\n",
    "\n",
    "####  Relational Classifier\n",
    "Используется информация о связях между наблюдениями.\n",
    "1. Инициализация - для нод, по которым мы точно знаем класс ставим веротяность (0.0 - для Negative примеров , 1.0 - для Positive примеров)\n",
    "2. Случайно выбираем ноду\n",
    "3. Обновляем вероятность POS класса как среднее от веротяностей соседей\n",
    "\n",
    "Процесс довольно быстро сходится к искомому ответу.\n",
    "\n",
    "Как скомбинировать два подхода? \n",
    "#### Local + Relative = Iterative Classification\n",
    "1. Делается локальный прогноз\n",
    "2. Классификатор применяется к тестовой выборке\n",
    "3. Рассчитываются новые фичи, учитывающие прогнозы соседей\n",
    "4. Обучается внешний классификатор, учитывающий и локальные, и соседские фичи\n",
    "5. Классификатор применяется к интересующему графу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Generation\n",
    "\n",
    "Большинство реальных сетей подчиняются степенному закону убывания степени вершины. Это сети, в которых есть хабы (узлы с очень большой степенью) и большое количество рядовых страниц с небольшими степенями.\n",
    "\n",
    "#### Модель генерации Erdos-Renyi\n",
    "Это самый простой алгоритм генерации случайного графа $G_{m,p}$:\n",
    "1. берем n точек\n",
    "2. для каждой пары точек с вероятностью p соединяем их\n",
    "\n",
    "Эта модель полностью лишена кластеризации. Здесь степень ноды в среднем равна np и распеределна биномиально, то есть нестандартные ноды в такой модели очень редки.\n",
    "\n",
    "Большинство реальных графов приниципально другие - везде есть кластеризация. Вот, например, отличия от социальной сети MSN:\n",
    "<img src=\"img/ng_er.png\" width=300>\n",
    "\n",
    "**Small World** сети - дословно сети типа \"мир тесен\", когда до любой ноды можно добраться за log(n) рукопожатий. Чем выше кластерзация сети, тем выше ее диаметр.\n",
    "\n",
    "<img src=\"img/ng_er2.png\" width=400>\n",
    "\n",
    "Есть такой теоретический эксперимент - у сети можно довольно эффективно уменьшить диаметр. Это называется Small World Model (1998). Для этого надо добавить случайности в граф - случайно выбранную ноду пересвязываем (rewire) с другой нодой. Аналог - познакомить человека со случайно выбранным человеком из другой страны, тогда его связи быстро расширяются. \n",
    "<img src=\"img/ng_er3.png\" width=550>\n",
    "\n",
    "На картинке ниже видим, что при этом диаметр сети уменьшается гораздо быстрее, чем коэффициент кластеризации. Это означает, что мы можем оставить кластерную структуру сети, но за счет нескольких добавленных связей среднее кол-во рукопожатий сильно уменьшается.\n",
    "<img src=\"img/ng_er4.png\" width=450>\n",
    "\n",
    "\n",
    "#### Degree distribution\n",
    "Один из способов описания структуры графа - вывод распределения степеней вершин (по X - степень, по Y - количество вершин или доля вершин). Ниже приведено распределение для социального графа пользователей Flickr:\n",
    "<img src=\"img/ng_1.png\" width=450></img>\n",
    "\n",
    "В большинстве реальных сетей если мы просто отрисуем это распрделеение (как в примере выше), ничего не будет видно - довольно мало узлов высокой степени. Поэтому при анализе распределнния обычно делают log-log преобразование:\n",
    "<img src=\"img/ng_2.png\" width=450></img>\n",
    "\n",
    "Теперь, еслм степени врешин араспрделены по степеноному закону, получается прямая линия, а ее наклон соотвествует степени в степенном распрделении.\n",
    "\n",
    "#### Heavy-tail распределения\n",
    "При анализе сетей, и в целом в статистике, важно понятие толстого хвоста у распределения.\n",
    "- Если у распределения тонкий хвост, выбросы маловеротяны и не влияют на основные характеристики этой случайной величины.\n",
    "- Если у распределения толстый хвост, выбросы должны учитываться.\n",
    "\n",
    "Формально, распределение имеет толстый хвост (heavy tail distribution), если не относится к классу экспоненциальных:\n",
    "$$\\lim_{x \\rightarrow \\infty} \\frac{P(X>x)}{e^{-\\lambda x}} = \\infty $$\n",
    "\n",
    "То есть например, хвост нормального распределения и хвост экспоненциального не толстые. \n",
    "Классический пример толостого хвоста - степенное распределение (Power Law).\n",
    "\n",
    "\n",
    "__Scale-free__ сети - те, которые описываются степенным распределением. PDF степенного распрдедения (Power Law) выглядит так: \n",
    "\n",
    "У распределения есть один параметр  - это минус степень этого распредедния.\n",
    "\n",
    "У Power Law есть важное свойство: матожидание определено только при >2, а дисперсия определена только при >3. То есть когда хвост совсем толстый, с ростом выборки, матожидание и дисперсия тоже будут расти.\n",
    "\n",
    "Чтобы определить по данным степень Power Law распрделения (scale factor), регрессию на PDF делать не нужно. Лучше делать регрессию на CCDF. Либо решать задачу максмильного правдоподобия, у нее есть аналитическое решение.\n",
    "\n",
    "#### Network Robustness\n",
    "Робастность сети - свойство сохранения размера наибольшего связанного компонента сети при удалении узлов.\n",
    "\n",
    "Scale-free сети с <3 робастны (устойчивы к удалению узлов). Причем как к случайным поломкам - random, так и злонамеренным атакам с удалением узлов с наибольшей степенью - target attacks.\n",
    "\n",
    "#### Network Resilience\n",
    "Network Resilience - устойчивость среднего пути к удалению узлов. Scale-free сети устойчивы к случайным поломкам (кдаление рядовых страниц сильно не вляиет) и неустойчивы к аттакам (удаление хабов сразу увеличивает средний путь).\n",
    "\n",
    "#### Preferential Attachment\n",
    "Preferential Attachment - это реализация принципа rich gets richer. При генерации сети, новые узлы присоединяются пропорционально текущим степеням узлов. В итоге получается самый что ни на есть Power Law.\n",
    "\n",
    "\n",
    "Есть много подходов к генерации графа, задействующих принцип preferential attachment, чтобы на выходе получился Power Law. Все они основаны на случайном выборе узлов или связей для соединения, а имеющиеся на текщий момент степени сами трансформируют веростность, чтобы получился preferential attachment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN Generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community structure\n",
    "\n",
    "<span style=\"color:blue\">Роль</span> - просто некий класс вершины, определяемый по структуре графа (например, может быть такая классификация: \"хаб\" / \"информативная страница\" / \"не определено\")\n",
    "\n",
    "<span style=\"color:blue\">Сообщество</span> - подграф, в котором наблюдается более плотная структура связей, чем в среднем по графу\n",
    "\n",
    "### Алгоритм RolX (определение ролей)\n",
    "Просто делается кластеризация нод на основе их положения в графе.\n",
    "1. Берем локальные фичи, которые нам изначально даны\n",
    "2. Добавляем базовые метрики ноды (все центральности, степени и прочее)\n",
    "3. Добавляем аналогичные (агрегированные, sum/mean) метрики соседей\n",
    "\n",
    "Далее делаем класетризацию.\n",
    "\n",
    "<img src = \"img/com1.png\" width=500>\n",
    "\n",
    "### Модулярность сети\n",
    "\n",
    "Модулярность - метрика кластеризованности сети.\n",
    "$$Q(G,S)=\\frac{1}{2m}\\sum_{s \\in S} \\sum_{i \\in S} \\sum_{j \\in S} (A_{ij}-\\frac{k_i k_j}{2m})$$\n",
    "\n",
    "где $m$ - число ребер в сообществе $s$, $k_i$ - степень узла i, $k_j$ - степень узла j\n",
    "\n",
    "Как получена эта формула:\n",
    "- метрика Q считается как разность между наблюдаемым числом ребер и прогнозируемым числом ребер, если бы кластерной структуры в сети не было.\n",
    "- элемент матрицы смежности $A_{ij}$ говорит о наличии ребра между i и j\n",
    "- $\\frac{k_i k_j}{2m} = P(i \\rightarrow j)$ - вероятность наличия в графе ребра $i \\rightarrow j$. Почему:\n",
    "    - в сообществе с m ребрами 2m дырок (spokes)\n",
    "    - у i-ой ноды $k_i$ дырок, у j-ой ноды $k_j$ дырок\n",
    "    - вероятность выбрать для ребра дырки нод i и j равна $k_i * k_j / 2m$\n",
    "- $\\frac{1}{2m}$ - нормировочный коэффициент\n",
    "\n",
    "### Алгоритм Luvain (определение сообществ)\n",
    "Алгоритм:\n",
    "1. каждая вершина - свое сообщество\n",
    "2. соединяем ноду с соседней так, чтобы увеличилась модулярность сети\n",
    "3. выбираем другую ноду, пересчитываем и так пока остаются варианты увеличить модулряность\n",
    "4. объединяем полученные сообщества в суперноду и повторяем тот же процесс но уже с супернодами\n",
    "В результате имеем дендрограмму сообщеcтв"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T03:45:52.095765Z",
     "start_time": "2020-08-15T03:45:52.054714Z"
    }
   },
   "source": [
    "## Knowledge Graphs\n",
    "\n",
    "Графы знаний - большие графы, содержащие вершины разных типов объединенные отношениями разных типов и целью которых является хранение и эффективное предоставление информации по запросам любой сложности, сформулрованным в терминах отношений.\n",
    "\n",
    "\n",
    "- Такие графы можно собирать руками, но в реальных проектах естественно,  они  наполняются автоматически (например в Google).\n",
    "\n",
    "\n",
    "- Все эти отношения (знания) можно сформулировать в виде тройки object - relation - subject, где object/subject два узла (однотипных или разнотипных), а relation - узел, характеризующий конкретное отношение\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:blue\">Метапуть</span> (metapath) - путь в графе знаний, записаный не через конкретные узлы, а через типы этих узлов. \n",
    "\n",
    "Например, зададим мета-путь \"Musician\" -> \"Plays\" -> \"Instrument\" и для него будет 2 разных релазиация:\n",
    "- Paul plays guitar\n",
    "- Ringo plays drums\n",
    "\n",
    "\n",
    "\n",
    "Метапути - удобный способ формулирования запросов к графу знаний.\n",
    "\n",
    "Возьмем граф цитирований в научных статьях и рассмотрим мета-пути стартующие из мета-ноды \"автор\" и заканчивающиеся в той же мета-ноде \"автор\":\n",
    "<img src=\"img/kg_mp1.png\" width=450>\n",
    "\n",
    "\n",
    "### Knowledge Graph Link Prediction\n",
    "\n",
    "Большинство графов знаний - неполные. Поэтому стандартная задача - предсказывать отношения между узлами.\n",
    "\n",
    "Пусть дана пара нод (s=start, t=target) и нужно оценить вероятность наличия между ними связи выбранного типа (edge type).\n",
    "\n",
    "Приведем пару алгоритмов заполнения связей.\n",
    "\n",
    "#### Алгоритм Path Ranking\n",
    "1. Перебираем все существующие мета-пути из $s$ в $t$\n",
    "2. Для выбранного мета-пути с помощью Random Walk генерируем случайные пути из вершины start и считаем, сколько из них завершается в finish\n",
    "3. С помощью логистической регрессии определяем веса мета-путей и выводим интегральный показатель\n",
    "\n",
    "\n",
    "$$score(s,t)=\\sum_{p \\in P}P(s \\rightarrow t | p) \\theta_P$$\n",
    "где $\\theta$ - вес мета-пути, $p$ - мета-пути из $s$ в $t$\n",
    "\n",
    "#### Алгоритм Path Predict\n",
    "\n",
    "Более общий подход - вместо вероятности P(s \\rightarrow t) в логистическую регрессию в качестве прищнаков добавляем всевозможные фичи, посчитанные на графе:\n",
    "$$score(s,t)=logit \\big( f(s \\rightarrow t | P_1), f(s \\rightarrow t | P_2) \\cdots f(s \\rightarrow t | P_n) \\big) $$\n",
    "\n",
    "### Node Similarity in Knowledge Graph \n",
    "Задача: для выбранной ноды s найти ближайший узел этого же типа в графе знаний. Типичный use-case - рекомендация схожих товаров.\n",
    "\n",
    "PathSim - нормализованное кол-во путей между s и t\n",
    "\n",
    "### Query Languages\n",
    "Cypher - язык запросов к графу знаний.\n",
    "\n",
    "Был реазиован в Neo4j.\n",
    "Менее популярная альтернатива - SparQL (не имеет отношения к Spark SQL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

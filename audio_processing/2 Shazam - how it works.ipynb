{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Concepts\n",
    "- Query - excerpt from a song tracked on a device\n",
    "- Reference - song in a database\n",
    "\n",
    "### How algorithm works (briefly)\n",
    "#### Data preprocessing\n",
    "1. We compute a spectrogram\n",
    "2. We retain only peaks on this spectrogram ($f_1$,$f_2$ ... $f_n$)\n",
    "3. We use some subset of peak pairs {($f_{t_1}$,$f_{t_2}$,$\\Delta_{t_1,t_2}$)} as a hash\n",
    "\n",
    "#### Prediction\n",
    "\n",
    "1. Using reverse index we get candidate songs.\n",
    "2. We choose a song that matches best\n",
    "\n",
    "There is no much detail on the implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting lecture by the author\n",
    "\n",
    "https://www.youtube.com/feed/history\n",
    "\n",
    "They started working on it in 1999:\n",
    "<img src=\"img/shazam_project.png\" width=550>\n",
    "\n",
    "Typical challenge in such applications - the noise.\n",
    "The level of noise is usually measured by SignalToNoise ratio\n",
    "- +20db\n",
    "- +10db\n",
    "\n",
    "At the moment state-of-the-art techniques included:\n",
    "- zero crossings - metric representing number of times the signal amplitute changes its sign; can also be used as a fingerprint in signal matching\n",
    "<img src=\"img/zerocrossing.svg\" width=250>\n",
    "- cross-correlation - we compare two signals by sliding query song along reference song. If there is a match there gonna be a peak\n",
    "<img src=\"img/cross_correlation.png\" width=300>\n",
    "\n",
    "    Minus - cross-correlation breaks with there is even a slight signal stretch\n",
    "\n",
    "\n",
    "- Spectral Flatness - a measure of tonality (jow uniform the signal is) with 1.0 for white noise and 0.0 for single frequency.\n",
    "\n",
    "\n",
    "### Idea #1 - Peaks\n",
    "\n",
    "Instead of using full spectrograms they tried to use just peak frequencies (the loudest sound at the moment). Turned out, it works very good.\n",
    "\n",
    "Also it allowed to decrease the size of a signal 500+ times (typical spectrogram back then had granularity of 512 bins).\n",
    "\n",
    "\n",
    "#### How robust this representation is?\n",
    "\n",
    "To experiment let's add some noise and count the number of peaks that would not change.\n",
    "\n",
    "No matter how much noise we add, there is always a few peaks that remain the same. \n",
    "\n",
    "As long as only few points are necessary to recover original song with high precision => peaks are quite robust!\n",
    "\n",
    "\n",
    "\n",
    "### Idea #2 - Combinatorial Hasing\n",
    "\n",
    "- Select anchor point\n",
    "- Select Target Zone - all points in interval succeding the anchor point\n",
    "- draw an edge\n",
    "- represent each edge as ($f_1$,$f_2$,$\\Delta t$)\n",
    "\n",
    "\n",
    "Only few edges are needed; Even fewer nodes are needed;\n",
    "\n",
    "\n",
    "### Idea #3 - Temporal Corerepondence\n",
    "\n",
    "How to distinguish between real matches and false matches? If there is a real match, some subset of matched points will be strictly aligned in time.\n",
    "\n",
    "Suppose there is a number of points that matched (including lots of false alarms). Let's plot them on a query-reference time offsets graph:\n",
    "- X axis = time offset in original song (reference)\n",
    "- Y axis = time offset in audio excerpt (query)\n",
    "\n",
    "If there is a real match, we will see a staright line of matching points:\n",
    "<img src =\"img/time_graph.png\" width=1000>\n",
    "\n",
    "Such straight line can be observed as a peak in a cross-correlation plot:\n",
    "<img src =\"img/time_histogram.png\" width=500>\n",
    "\n",
    "#### Is there any noise reduction in the algorithm?\n",
    "No\n",
    "\n",
    "### Algoritm Robustness\n",
    "\n",
    "Audio modifications that hinders recognition:\n",
    "- tempo\n",
    "- pitch\n",
    "\n",
    "To get modification-invariant fingerprints you should use ratios instead of absolute value tuples.\n",
    "\n",
    "For example, \n",
    "$$\\frac{f_1}{f_2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a good paper with a review:\n",
    "\n",
    "http://coding-geek.com/how-shazam-works/\n",
    "\n",
    "Unforunately a bit outdated.\n",
    "\n",
    "Here is how data preprocessing looks like:\n",
    "\n",
    "<img src = \"img/shazam_scheme.jpg\">\n",
    "\n",
    "\n",
    "1. Computes a spectrogram\n",
    "2. Retains only peaks from this spectrogram - this gonna br an audio fingerprint\n",
    "3. Constructs a hash from it and compares to song database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Research\n",
    "\n",
    "### Sonnleitner\n",
    "[Dissertation](http://www.cp.jku.at/research/papers/Sonnleitner_Dissertation.pdf) (2017)\n",
    "\n",
    "Goal: propose methods, more robust to scaling and other signal modifications.\n",
    "\n",
    "- Spectrograms are constructed using STFT (short time fourier transform).\n",
    "\n",
    "    It decomposes signal into frequencies, but only in a local neighborhood of the signal => also depends on time:\n",
    "\n",
    "    $$\\mathbf{STFT}\\{x(t)\\}(\\tau,\\omega) \\equiv X(\\tau, \\omega) = \\int_{-\\infty}^{\\infty} x(t) w(t-\\tau) e^{-i \\omega t} \\, d t$$\n",
    "\n",
    "- They introduce Quad (quadruple) fingerprints instead of pairs.\n",
    "\n",
    "    Let's consider a peak spectrogram.\n",
    "    Quads are represented by four-tuples of sorted peaks: A, B, C, D so that all of them are contained within a region formed by A and D. \n",
    "\n",
    "    Relative nature of construction of these tuples makes those fingerprints scale-inveriant.\n",
    "\n",
    "- Only valid peaks are taken into account, weak peaks on uniform regions are rejected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T11:19:31.144883Z",
     "start_time": "2021-02-02T11:19:31.065682Z"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

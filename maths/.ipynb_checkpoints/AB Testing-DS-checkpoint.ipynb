{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For managers\n",
    "\n",
    "Development of any product requires a constant search for a better solution; each change is meant to make the product better.\n",
    "\n",
    "How do we know if a new feature is potentially useful apart from common reasoning? \n",
    "To some extent offline testing  helps us. Offline, also called retrospetctive, testing we don't run product in production, we mathematicallt model how change would work. \n",
    "\n",
    "Offline testing is a necessary step for any feature. But unfortunately it's very limited in its power. You simply can't model everything, you can't take every possible factor into account, such kind of prediction would be unreliable, prediction how feature would work in a new setting.\n",
    "\n",
    "That's why it's insufficient, you also need online tests - to see how it works in production.\n",
    "In software development this is called A/B testing, because you compare two alternatives A and B. In a broader sense, hypotesys testing in the design of experiment.\n",
    "\n",
    "So, the idea is simple - just run two alternatives and see wich one is better. \n",
    "\n",
    "But why dedicate a whole lecture to it? Because there are two complications to the process:\n",
    "1. you have to guarantee the same conditions for both alternatives as well target environment, otherwise your conclusion could be wrong and you would not know that it's wrong\n",
    "2. Second point is even more important - your conclusion could wrong simply by chance. This is because that we observe is probabilistic customer behavior is prone to uncertainty. So you need to somehow assess the trustworthiness of your conclusion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing\n",
    "\n",
    "There are lots of online calculators for A/B tests.\n",
    "\n",
    "For example this one:\n",
    "https://abtestguide.com/calc/\n",
    "\n",
    "#### Input\n",
    " - N1 (visitors in group A)\n",
    " - N2 (visitors in group B)\n",
    " - conversions 1 (number of conversions, or other successful actions)\n",
    " - conversions 2 (number of conversions, or other successful actions)\n",
    "\n",
    "Here is a typical output of the A/B test\n",
    "\n",
    "<img src =\"img/ab_test_calculator.png\" width=750>\n",
    "\n",
    "\n",
    "Let's explore it:\n",
    "- Conversion Rate = implementation of the binomial random variable divided by N  \n",
    "\n",
    "        success rate, the same scale as p and q;\n",
    "\n",
    "- Standard Error = Standard Deviaton of Conversion Rate\n",
    "\n",
    "        depends on p and N;\n",
    "        higher SD means larger difference is required to be significant\n",
    "\n",
    "- Delta = difference in binomial variables implementation\n",
    "\n",
    "        for example, 5 successful actions more in group A\n",
    "\n",
    "- Relative Uplift = normalized delta\n",
    "\n",
    "        for example, 3% more successful actions in group A\n",
    "        \n",
    "- Expectation of Delta\n",
    "\n",
    "- Standard Error = standard deviation of Average\n",
    "\n",
    "- Standard Error of difference\n",
    "\n",
    "- z-score = observed delta on a scale of its standard deviations\n",
    "\n",
    "        the more extreme delta is, the higher likelihood of signifcant differnece;\n",
    "        it is two-side Student test sstatistic\n",
    "\n",
    "- p-value - probability of observing more extreme z-score values in case of H0\n",
    "\n",
    "        must be maximum 1-5% to be negligible\n",
    "\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematics of A/B testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli distribution\n",
    "\n",
    "Bernoulli trial is a binary random variable that yeilds \"1\" (success) with probability $p$ and \"0\" (failure) with probability $1-p$.\n",
    "\n",
    "As any proper random variable, it has its own:\n",
    "1. Expectation \n",
    "   \n",
    "   $E [\\xi] = p$\n",
    "   \n",
    "   \n",
    "2. Variance\n",
    "\n",
    "    $V[\\xi] = \\sigma_{\\xi}^2 = p(1-p)$\n",
    "\n",
    "To illustrate these values just sample from Bernoulli distribution n times. \n",
    "\n",
    "On average it will yeild 1 in $p$ of the times and its variance.\n",
    "\n",
    "Notice that $V[\\xi]$:\n",
    "1. Depends on $p$. Closer $p$ is to 0 or 1, the less variance we observe. The most \"variable\" case is when $p = 0.5$. In that case variance equals 1/4.\n",
    "2. It depends quadratically\n",
    "\n",
    "<img src=\"img/variance.png\" width=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binomial distribution\n",
    "\n",
    "When we repeated sampling n times we constructed a series of Bernoulli trials which is a base for another relevant distribution - Binomial.\n",
    "\n",
    "Binomial random variable represents a sum of series of independent Bernoulli trials. \n",
    "\n",
    "$$\\xi = \\xi_1 + \\xi_2 + \\dots \\xi_n$$\n",
    "\n",
    "The number of succeses in a series of $n$ trials is distributed according to binomial distirbution with parameter $p$.\n",
    "\n",
    "Expected number of successes is:\n",
    "\n",
    "$$E[\\xi] = \\sum_i \\xi_i = \\sum_i p = np$$\n",
    "\n",
    "Variance of the successes is:\n",
    "\n",
    "$$V[\\xi] = \\sum V[\\xi_i] = \\sum p(1-p) = np(1-p)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. One-sample Srtudent test\n",
    "\n",
    "Let's consider a toy case. We what to hypitesis that  to predefined constant.\n",
    "\n",
    "#### Two-samples Student test\n",
    "\n",
    "Suppose there are two samples A and B - they represent alternative scenarios that are being compared. Observed success counts are $X_A$ and $X_B$ respectively.\n",
    "\n",
    "Observed deviance $X_A - X_B$ is not necessary the result of the systematic differences in scenarios. It may be attributed to high variance in our Binomial trials as well. The goal of Student T-test is to tell whether it is the first or the second case.\n",
    "\n",
    "In order to assess the signfcaince of the difference we need to explore $X_\\Delta = X_A - X_b$.\n",
    "\n",
    "Under $H_0$ $X_\\Delta$ is a random variable. If we know its distribution, we can easily calculate the p-value of it.\n",
    "\n",
    "$$E[X_\\Delta] = E[X_A] - E[X_B] = 0 - 0 = 0$$\n",
    "\n",
    "$$V[X_\\Delta] = $$\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{\\sigma_{\\xi_1}}{n_1} + \\frac{\\sigma_{\\xi_2}}{n_2}}$$\n",
    "\n",
    "$$ t = \\frac{X_\\Delta - E[X_\\Delta]}{\\sigma_{\\Delta}} = \\frac{X_{\\Delta}}{\\sqrt{\\frac{\\sigma_{\\xi_1}}{n_1} + \\frac{\\sigma_{\\xi_2}}{n_2}}}$$\n",
    "\n",
    "Generally Student test requires <u>normal</u> distribution of analyzed samples. For example, when we compare page loading times for 2 apge versions. \n",
    "\n",
    "There is however relaxation when distributions are only approximately normal (like binomial distributions with satisfactory sample sizes). It's called Welsch test.\n",
    "https://en.wikipedia.org/wiki/Welch%27s_t-test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

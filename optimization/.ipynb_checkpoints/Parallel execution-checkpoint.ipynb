{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ноутбук в процессе разработки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embarassingly Parallel Problem** - задача,  которую можно легко разбить на составные части (её вычисление не требует комбинирования промежуточных результатов).\n",
    "\n",
    "Примеры легко параллелизуемых задач:\n",
    "- вычисление базовых статистик\n",
    "- построение ансамблей классификаторов (random forest)\n",
    "- расчет статистик путем многократных симуляций (например, monte-carlo simulation, кросс-валидация или grid search)\n",
    "\n",
    "Gradient Boosting ансамблирование не является embarassingly parallel задачей, так как каждая итерация зависит от результата предыдущей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уровни параллельного выполнения:\n",
    "0. Sequential\n",
    "1. Multiple threads (within single process)\n",
    "2. Multiple processes (on a single machine)\n",
    "3. Multiple machines (a cluster)\n",
    "\n",
    "**Поток vs Процесс**\n",
    "\n",
    "Поток - часть процесса. Он работает в едином адресном пространтсве. Все потоки в рамках одного процесса имеют доступ к ранее созданным переменным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параллельное выполнение в Python (Threading)\n",
    "\n",
    "Цель потоков - иметь возможность параллельно запустить (синхронно или асинхронно) несколько подзадач. Использование тредов не дает выигрыша по времени выполнения, важна именно параллельность.\n",
    "\n",
    "Запускается так:\n",
    "\n",
    "    t = Thread(target = func, args = ())\n",
    "    t.start()\n",
    "\n",
    "Второй способ создать поток:\n",
    "\n",
    "    class myThread(Thread):\n",
    "        def run()\n",
    "\n",
    "Можно запускать много потоков:\n",
    "\n",
    "    ThreadPoolExecutor(max_workers=100)\n",
    "    pool.map(func(), range(100))\n",
    "\n",
    "    По умолчанию, все переменные потока создаются в общей памяти процесса. Чтобы \n",
    "\n",
    "Можно работать с локальными данными:\n",
    "\n",
    "    locals = threading.local()\n",
    "    locals.x = 1\n",
    "\n",
    "**Barrier** - останавливает выполнение, пока все потоки не дойдут до него\n",
    "\n",
    "**Event** - потоки подписываются на событие методом wait() и стартуют только когда поток устанавливает его set()\n",
    "\n",
    "**Timer** - поток, который запускается через n секунд\n",
    "\n",
    "**Lock** - позволяет выполнять только один поток в один момент времени\n",
    "\n",
    "    lock = Lock(blocking = True, timeout = -1)\n",
    "    \n",
    "    lock.acquire()\n",
    "    __do_some_work__()\n",
    "    lock.release()\n",
    "\n",
    "Если занято, то поток может блокироваться (blocking = True) или просто возвращать False (blocking = False). Также можно настроить, что поток будет стучаться ещё в течение timeout.\n",
    "\n",
    "**RLock** - Lock, который может много раз блокировать вход в рамках потока. Соотвественно столько же раз он должен сделать release().\n",
    "\n",
    "**Semaphore** - не позволяет выполнять более n параллельных потоков. Если параметр value = 1, то логика работы аналогична классу Lock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параллельное выполнение в Python (Multiprocessing)\n",
    "   \n",
    "    import multiprocessing\n",
    "\n",
    "- Объект Process() создает новый процесс, в котором выполнеятся функция f():\n",
    "\n",
    "        p = Process(target=f, args=())\n",
    "        p.start()\n",
    "        p.join()\n",
    "    \n",
    "    Метод join() говорит, что теперь выполнение синхронное.\n",
    "\n",
    "\n",
    "- Если предполагается использовать много процессов, удобнее работать сразу с пулом процессов:\n",
    "\n",
    "        # Создать пул из 25 процессов\n",
    "        pool = Pool(25)\n",
    "        \n",
    "        # в каждом процессе запустить функцию f\n",
    "        pool.map(f, args)\n",
    "        \n",
    "        # запустить f\n",
    "        pool.async_apply_async()\n",
    "\n",
    "Для межпроцессного взаимодействия используются три типа объектов:\n",
    "- **Queue**\n",
    "    - Создается очередь q = Queue() и передается ссылкой в новый процесс\n",
    "    - Из основного процесса можно читать то, что процесс туда пишет q.get()\n",
    "    \n",
    "    \n",
    "- **Pipe**\n",
    "    - при создании пайпа Pipe() создаются две ссылки - одна передается параметром в новый процесс\n",
    "    - из основного процесса можно читать по второй ссылке\n",
    "\n",
    "\n",
    "- **Lock**\n",
    "    - создается Lock()\n",
    "    - передается параметром в дочерние процессы\n",
    "    - внутри каждый процесс его запирает, выполняет нужные действия и открывает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также есть классы для Shared Memory\n",
    "- **Value** - скаляр\n",
    "- **Array** - массив значений\n",
    "\n",
    "Создаются разделяемые переменные\n",
    "- передаются параметрами в дочерние процессы\n",
    "- оттуда могут по ссылке изменяться\n",
    "\n",
    "Класс **Server Manager** позволяет создавать shared объекты произвольного типа.\n",
    "Их так же можно передавать параметрами в дочерние процессы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Встроенный шедулер в Python\n",
    "\n",
    "**Sched** - встроенный в питон простенький шедулер\n",
    "\n",
    "    import sched\n",
    "\n",
    "При создании шедулера задаётся функция времени (по умолчанию time.time) и функция ожидания (по умолчанию time.sleep)\n",
    "\n",
    "    Scheduler(time_func=, delay_func=)\n",
    "\n",
    "Затем добавляются задачи:\n",
    "\n",
    "    event_id1 = s.enter(delay=10, priority=1, action=func1())\n",
    "    event_id2 = s.enter(delay=15, priority=2, action=func2())\n",
    "    event_id3 = s.enter(delay=20, priority=1, action=func3())\n",
    "\n",
    "Можно убрать какую-то задачу:\n",
    "\n",
    "    s.cancel(event_id3)\n",
    "\n",
    "И затем все это запускается на выполнение:\n",
    "\n",
    "    s.run()\n",
    "\n",
    "Посмотреть актуальную очередь можно так:\n",
    "\n",
    "    s.queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Очереди (Queue)\n",
    "\n",
    "Бесконечная очередь,  в которую можно из параллельных потоков добавлять и забирать элементы. При подключении обеспечитвается блокировка.\n",
    "\n",
    "Помимо FIFO варианта (по умолчанию), есть ещё LIFO (стек) и PriorityQueue.\n",
    "\n",
    "    q = Queue()\n",
    "\n",
    "Аналог collections.deque, но там без блокировки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо иллюстрируется на примере реализации кординатора задач и рабочих потоков.\n",
    "\n",
    "Опишем поток, который \n",
    "1. подключается к очереди и ждёт задачу:\n",
    "        q.get() \n",
    "2. выполняет задачу\n",
    "        do_work()\n",
    "3. и оповещает очередь, что сделал задачу:\n",
    "        q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker():\n",
    "        while True:\n",
    "            item = q.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            do_work(item)\n",
    "            q.task_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим 20 рабочих потоков, каждый пытается подключиться к очереди"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()\n",
    "    threads = []\n",
    "    for i in range(num_worker_threads):\n",
    "        t = threading.Thread(target=worker)\n",
    "        t.start()\n",
    "        threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основном потоке запуливаем данные в очередь, чтобы потоки начали работать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in source():\n",
    "    q.put(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ждем, когда все потоки свои задачи выполнят и шлем им сигнал остановки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.join()\n",
    "\n",
    "for i in range(num_worker_threads):\n",
    "    q.put(None)\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск внешних процессов (Subprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый способ запуска шелл-команд в питоне\n",
    "\n",
    "    import os\n",
    "    os.system(\"ls\")\n",
    "\n",
    "Не выводит результат, нет контроля над выводом. Лучше использовать subprocess.\n",
    "\n",
    "    import subprocess\n",
    "    subprocess.run(\"ls\")\n",
    "\n",
    "А ещё лучше Popen - конструктор, конструктор который позволяет \n",
    "- перенаправлеть ввод/вывод\n",
    "- передавать длинные строки параметров\n",
    "- делать интерактивные сессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тип Futures\n",
    "\n",
    "    import concurrent.futures\n",
    "\n",
    "Здесь вводятся два важных класса:\n",
    "- ThreadPoolExecutor\n",
    "- ProcessPoolExeutor\n",
    "\n",
    "Оба асинхронно запускают произвольный набор потоков или процессов. \n",
    "\n",
    "Есть два метода запуска:\n",
    "\n",
    "- submit(func, args) - запускает один поток/процесс\n",
    "- map(func, args) - запускает несколько потоков/процессов для списка аргументов\n",
    "\n",
    "Кроме того, вводится **Future** - специальный тип, ссылка на асинхронно запущенный поток или процесса.\n",
    "\n",
    "submit() возвращает Future, а map() итератор над обхектами типа Future\n",
    "\n",
    "Атрибуты запущенного процесса:\n",
    "- result() - пытаемся прочитать результат выполнения. Ждем timeout секунд, если результата пока нету, выводим Exception.\n",
    "- cancel() - отменить процесс/поток\n",
    "- running() - проверяем, что выполняется\n",
    "- done() - проверяем, что завершен\n",
    "\n",
    "wait(fs) - выводим, кто завершен, кто выполняется\n",
    "as_completed(fs) - итератор над будущими значениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотека Joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Joblib is a library for simple parallel programming __primarily developed and used by the Scikit Learn community__. As of version 0.10.0 it contains a plugin mechanism to allow Joblib code to use other parallel frameworks to execute computations\n",
    "\n",
    "**Цель библиотеки:** конвертация питоновского кода в пайплайны - наборы преобразований, которые вычисляются как можно реже.\n",
    "\n",
    "### Основные функции\n",
    "\n",
    "##### 1) Параллелизация\n",
    "\n",
    "Шаблон использования Joblib:\n",
    "\n",
    "    parallel = Parallel(n_jobs=-1, backend='loky')\n",
    "    input_generator = delayed(func)(partition) for partition in inputs\n",
    "    parallel(input_generator)\n",
    "\n",
    "Вторая строчка - это <a href=https://www.python.org/dev/peps/pep-0289/>generator expression</a>. Аналог list compregension, но без скобок - считается во время выполнения.\n",
    "\n",
    "delayed() - обертка для функции\n",
    "    \n",
    "Основные API функции в Joblib - это фронт, есть ешё бэкенд - конкретный способ параллелизации.\n",
    "\n",
    "- Loky\n",
    "- Multithreading\n",
    "- Multiprcoessing\n",
    "\n",
    "Плюс можно регистрировать любые свои бэкенды.\n",
    "\n",
    "Например, можно поставить Dask backend, тогда появляется возможность запускать параллельные sklearn модели на кластере.\n",
    "\n",
    "##### 2) Кэширование результатов\n",
    "    \n",
    "    func = Memory.cache(func)\n",
    "    func(1) # здесь кэшируется\n",
    "    func(1) # здесь берется закэшированный результат\n",
    "\n",
    "##### 3) Сериалзиация\n",
    "\n",
    "По аналогии с pickle есть методы \n",
    "\n",
    "    dump()\n",
    "    load()\n",
    "    \n",
    "но работает эффективнее.\n",
    "\n",
    "##### Интеграция в Scikit-Learn\n",
    "\n",
    "Joblib включен в Scikit-Learn и испрользуется в реализации некоторых методов. Например, можно посмотреть его использование в методе fit() алгоритма model_selection.GridSeachCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотека DASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более глобальная библиотека. Цель та же.\n",
    "\n",
    "The single machine scheduler is more useful to individuals (more people have personal laptops than have access to clusters) and probably accounts for 80+% of the use of Dask today. On the other hand, the distributed machine scheduler is more useful to larger organizations like universities, research labs, or private companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask DataFrame - распределенная версия Pandas датафрейма. Частично поддерживает API.\n",
    "\n",
    "Dask относится к Python примерно так же как PySpark к Python.\n",
    "\n",
    "Dask.Delayed - обертка для функции, которая указывает, что функция должна выполняться в lazy-режиме. На вход подается либо константа, либо другая delayed-функция.\n",
    "\n",
    "Futures - результаты работы стратовавших background процессов, значения которых известны только после выполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed, compute\n",
    "from time import sleep\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем функцию, которую нужно применить\n",
    "def process(x):\n",
    "    y = 0\n",
    "    for x in range(1000000):\n",
    "        y = y - x*x + random.randint(0,10000) * random.randint(0,10000)\n",
    "    return y+1\n",
    "\n",
    "# задаем входы\n",
    "inputs = range(10)\n",
    "\n",
    "# формирваем список функций-оберток\n",
    "values = [delayed(process)(x) for x in inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала попробуем выполнить последовательно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.8 s, sys: 356 ms, total: 1min\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%time results = [process(x) for x in inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем выпонение в несколько потоков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.9 ms, sys: 39.2 ms, total: 109 ms\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%time results = compute(*values, scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.9 s, sys: 735 ms, total: 59.7 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%time results = compute(*values, scheduler='threads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У меня на ноутбуке (4 ядра) получились такие резульаты:\n",
    "\n",
    "##### Sequential\n",
    "Wall time: 1min 1s\n",
    "##### Multithread\n",
    "Wall time: 1min\n",
    "##### Multiprocess\n",
    "Wall time: 36.1 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кейсы применения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Параллельный apply в Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# Загрузим какой-нибудь датасет\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris = pandas.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "# Опишем фукнкцию для обработки данных, которую нужно применить\n",
    "def func(df_partition):\n",
    "    df_partition['new_column1'] = 1\n",
    "    df_partition['new_column2'] = 2\n",
    "    df_partition['new_column3'] = 3\n",
    "    return df_partition\n",
    "\n",
    "# Напишем функцию-обертку, которая внутри будет разбивать на составные части и выполнять параллельно\n",
    "def parallel_apply(df, func, n_partitions=4):\n",
    "    \n",
    "    # Делим датасет на n равных частей\n",
    "    df_split = numpy.array_split(df, n_partitions)\n",
    "    \n",
    "    # Создаем пул процессов\n",
    "    pool = Pool(n_partitions)\n",
    "    \n",
    "    # Запускаем процесс для каждой части с помощью map()\n",
    "    df = pandas.concat(pool.map(func, df_split))\n",
    "    \n",
    "    pool.close()\n",
    "    \n",
    "    pool.join()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Можем применять для любых датасетов\n",
    "new_df = parallel_apply(iris, func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old dataset shape = (150, 4), new dataset shape(150, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"old dataset shape = {}, new dataset shape{}\".format(iris.shape, new_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pandarallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть доморощенная бибилотека, в которой реализован этот подход. Только тут он используется не как функция, а как переопределнный метод класса DataFrame - удобно!\n",
    "\n",
    "Установка:\n",
    "\n",
    "    pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "\n",
    "def func(x):\n",
    "    return sin(x**2)\n",
    "\n",
    "df.parallel_apply(func, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice and simple video course here:\n",
    "\n",
    "https://www.youtube.com/watch?v=rjpbE-X23wc\n",
    "\n",
    "## Common Tasks\n",
    "\n",
    "#### Navigation tasks\n",
    "- localization\n",
    "- path planning\n",
    "- map building\n",
    "\n",
    "Vision based navigation - thread based only on imaging.\n",
    "\n",
    "### Localization\n",
    "\n",
    "Localization = task to determine the state of an agent (location or pose) based on sensor information. Sensor information is not GPS. In many cases one observation is not enough, so the agent must move to build to get the full image of the surrounding area.\n",
    "\n",
    "Approaches:\n",
    "- Bayes Filter\n",
    "- Kalman Filter\n",
    "- Extended Kalman Filter\n",
    "- Particle Filter\n",
    "\n",
    "### Path Finding\n",
    "__Input:__ Map of the area\n",
    "\n",
    "__Output:__ Optimal path from start point to goal\n",
    "\n",
    "Algorithms:\n",
    "- A*\n",
    "- RRT\n",
    "- RRT*\n",
    "\n",
    "### SLAM\n",
    "Simultaneous Localization and Mapping\n",
    "\n",
    "__Task__: Build a map of the area using measurements. \n",
    "\n",
    "__Example:__ https://www.youtube.com/watch?v=qpTS7kg9J3A\n",
    "\n",
    "To accomplish this task a robot needs to move a lot because:\n",
    "- there are occlusions\n",
    "- there is ambiguity - it's hard to localize when there are few landmarks in the area. It becomes possible to accurately determine the location when many observations are compared\n",
    "\n",
    "Comon approaches:\n",
    "- Graph optimization\n",
    "- Graph with Landmarks\n",
    "\n",
    "### Neural SLAM\n",
    "Since 2015 neural based methods became dominant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes filter\n",
    "\n",
    "__Bayes Filter__ (or __Recursive Bayesian estimation__) - is a recursive probabilistic process that continuously updates current distribution of a value of interest.\n",
    "\n",
    "Position prediction for Localization problem is a good example of Bayes filter. It's good example of Hidden Markov Model (HMM)\n",
    "\n",
    "<img src=\"img/bayes_filter.png\" width=300>\n",
    "\n",
    "- __X__ are unobserved values (agent position)\n",
    "- Each X directly depends only on its previous value\n",
    "- z are observed values (position measurement) and are independent of each other\n",
    "\n",
    "### BF for Localization Problem\n",
    "\n",
    "Let's denote our current estimate of position distribution as $bel(x)$.\n",
    "\n",
    "<img src=\"img/bayes.png\" width=150>\n",
    "\n",
    "Then each step of the process would look like this:\n",
    "\n",
    "$$bel(x_t) = \\eta \\cdot P(z_t | x_t) \\cdot \\int P(x_t | x_{t-1}, u_{t-1}) \\cdot bel(x_{t-1} ) d x_{t-1} $$\n",
    "\n",
    "The step consits of 2 parts:\n",
    "- updating using <u>motion model</u>\n",
    "- correcting using <u>observation model</u>\n",
    "\n",
    "#### Motion Model\n",
    "With Motion Model we predict where the robot could be now, given that previous position was $x_{t-1}$ and the control applied was $u_{t}$\n",
    "\n",
    "$$ \\hat{bel(x_t)} = \\int P(x_t | x_{t-1}, u_{t}) \\cdot bel(x_{t-1} ) d x_{t-1} $$\n",
    "\n",
    "Let's explore this expression:\n",
    "- $bel(x_{t-1})$ - estimated robot localization from the previous step (distribution)\n",
    "- $P(x_t | x_{t-1}, u_{t-1})$ - distribution of a new position given starting point $x_{t-1}$ and control $u_t$\n",
    "\n",
    "Then we intergrate over all possible starting points to get a posterior ditsribution of the robot position\n",
    "\n",
    "#### Observartion Model\n",
    "\n",
    "Then we get an observed value $z_t$ and reweight our distribution $bel(x_{t-1})$ according to the likelihood of this value $P(x_t| x_t)$:\n",
    "\n",
    "$$ \\hat{bel(x_t)} = P(z_{t} | x_{t}) \\cdot bel(x_{t-1} ) $$\n",
    "\n",
    "<img src=\"img/kalman_filter.jpg\" width=500>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filter\n",
    "\n",
    "Let's consider our Bayes Filter.\n",
    "\n",
    "If these three conditions are held:\n",
    "1. Distribution of Motion Model is normal\n",
    "2. Distribution of Measurement Model is normal\n",
    "3. Motion is linear\n",
    "\n",
    "=> this expression becomes __Kalman Filter__.\n",
    "\n",
    "How to write linearity conditions:\n",
    "- $x_t = A_tX_{t-1} + B_tu_t + \\epsilon_t$\n",
    "- $z_t = C_tx_t + \\delta_t$\n",
    "\n",
    "Here we state that the motion depends on previous state $X_{t-1}$ and current control $u_t$ and the dependency is purely linear with some random noise $\\epsilon_t$.\n",
    "\n",
    "Measurement is also imperfect with $C_t$ - measurement bias and random noise $\\delta_t$.\n",
    "\n",
    "Both noises ($\\epsilon_t$ and $\\delta_t$) must be Gaussian.\n",
    "\n",
    "Noises $\\epsilon_t$ and $\\delta_t$ are independent in time. But they can have non-diagonal convariance matrices ($R_t$ and $Q_t$ respectively)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Solution\n",
    "\n",
    "To get formulas we simply plug Gaussian distributions in the formula. They may seem a bit involved but they convey very basic idea.\n",
    "\n",
    "On Prediction step we estimate the mean and covariance of the location:\n",
    "- $\\mu_t = A \\mu_{t-1} + B_t u_t$\n",
    "- $\\Sigma_t = A_t \\Sigma_{t-1} A_t^T + R_t$\n",
    "\n",
    "On the Correction step we calculate Kalman Gain and compute weigted average of the location estimate and the measurement:\n",
    "- $K_t = \\Sigma_t C_t^T (C_t \\Sigma_t C_t^T + Q_t)^-1$\n",
    "- $\\mu_t = \\mu_t + K_t (z_t - C_t \\mu_t)$\n",
    "- $\\Sigma = (I-K_t C_t) \\Sigma_t$\n",
    "\n",
    "__Kalman Gain__ in the formula above - weights how important is use measurement instead of predicted position\n",
    "\n",
    "\n",
    "\n",
    "#### The way it's written on Wikipedia\n",
    "\n",
    "They use a different notation but the formulas are the same:\n",
    "\n",
    "<img src = \"img/kalman_wiki.png\" width=500>\n",
    "\n",
    "### Extended Klaman Filter\n",
    "It's a non linear version of Kalman filter.\n",
    "\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Filter\n",
    "\n",
    "The term was coined in 1996, Del Moral\n",
    "\n",
    "Particle Filter is a sampled implementation of the Bayes filter described above. But instead of dealing with cumbersome continuous distributions, we deal with their samples. On each step we express our location belief as a weighted sample of points (particles).\n",
    "\n",
    "Approximation of continuous distribution with a sample = Monte-Carlo simulation. Thus localization using Paritcle Filter is also called __Monte-Carlo localization__.\n",
    "\n",
    "Note that it's localization problem, not a SLAM, so it requires a map!\n",
    "\n",
    "How exactly to approximate arbitrary distriubtion with a sample?\n",
    "\n",
    "#### ASIDE1: Importance sampling\n",
    "- __Proposal distribution__ - some approximate distribution that is easy to sample from (for example Gaussian).\n",
    "- __Target distriubtion__ - some complex distribution that we need to approximate\n",
    "\n",
    "\n",
    "1. Generate a sample $x$ from a simple approximation\n",
    "2. Compare the probability $P_{approx}(x)$ to target distribution $P_{target}(x)$  (it's an easy thing to do)\n",
    "3. Compute a weight $w(x) = \\frac{P_{approx}(x)}{P_{target}(x)}$. It acts as a sampled discrete approximation of the target distribution\n",
    "\n",
    "#### ASIDE2: Particle Filter Algorithm (General)\n",
    "1. Sample from proposal distribution\n",
    "2. Compute weights\n",
    "3. Resample - draw from the new discrete distribution the same number of points\n",
    "\n",
    "### Particle Filter For Localization\n",
    "Update step:\n",
    "1. For each particle in the current set we apply motion model and sample from it - we get possible position of a particle \n",
    "2. Make an observation \n",
    "3. For each possible position compute the likelihood of observation. Thus we get points of high location probability.\n",
    "4. Resample - draw from the new discrete distribution the same number of points. Thus we spawn more points the same as high probability points\n",
    "\n",
    "Nice alogirthm explanation here: [Youtube](https://www.youtube.com/watch?v=OM5iXrvUr_o)\n",
    "\n",
    "#### 1-D illustration\n",
    "Each update step can be illustrated with the following scheme:\n",
    "<img src=\"img/particle1.png\" width=500>\n",
    "\n",
    "1. Get initial belief\n",
    "2. Resample according to this belief\n",
    "3. Use the motion model while resampling\n",
    "4. Explore the likelihood of the observation\n",
    "5. Update our belief using observation likelihood for each candidate\n",
    "\n",
    "#### 2-D illustration of the method\n",
    "Assume the task is to determine the location of a robot in house.\n",
    "\n",
    "Alogirthm:\n",
    "1. Initial probability is uniform \n",
    "\n",
    "        particles form a random grid\n",
    "\n",
    "2. Robot makes a snapshot of its surroundings\n",
    "\n",
    "        records an observation\n",
    "    \n",
    "3. Initial guesses are reweighed according to the likelihood of robot position given the image\n",
    "\n",
    "        a few points get a really high score\n",
    "\n",
    "4. Point cloud of guesses is resampled according to assigned weights\n",
    "\n",
    "        most new points are generated near the high score points\n",
    "\n",
    "<img src=\"img/mcl1.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squared Error\n",
    "\n",
    "It's a main boulding block for SLAM techniques\n",
    "\n",
    "Determine the most probable location based on sensor measurement\n",
    "\n",
    "- $x$ - position\n",
    "- $f_i(x)$ - singal from the sensor $i$ in point x\n",
    "- $\\{f_1(x) ... f_n(x)\\}$ - all signals from sensors in state x\n",
    "- $\\{z_1 ... z_n\\}$ - all signals from sensors in state x\n",
    "\n",
    "$$e_i = e^T \\cdot \\Omega \\cdot e$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Graph optimization\n",
    "\n",
    "Idea: let robot make a circular movement with periodic snapshots of its surroundings. Those observations make up a graph in which edge's weight corresponds to measurements similarity. Then we correct locations so that map would be \n",
    "\n",
    "Main structure - Graph of observations. Each edge represents some kind of constraint. In most cases it's an estimated robot movement between two measurements.\n",
    "\n",
    "Can be viewed as a system of rubber sticks that can be modified to most precisely explain observartions.\n",
    "\n",
    "Something similar to Multidimensional Scaling.\n",
    "\n",
    "All transformations are done in __Homogenuous coordinates__. Convenient way to encode sequqnces of transformations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Graph With Landmarks\n",
    "\n",
    "A concept similar to ordinary Pose Graph, but here we have additional constraints - points on map called landmarks. More constraints => we are getting more precise mapping.\n",
    "\n",
    "Here we have two types of nodes:\n",
    "- robot positions\n",
    "- landmark positions\n",
    "\n",
    "Edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A*\n",
    "\n",
    "It's a tree-based method. We iteratevely construct and navigate a transition tree.\n",
    "\n",
    "__Input:__ Grid with start cell and finish cell\n",
    "\n",
    "Method operates on three metrics that are computed on each visited cell of the grid:\n",
    "- g(x) = gained - path length from the start point to X\n",
    "- h(x) = heuristic - (admissible) estimate of the path length from X to the end point\n",
    "- f(x) = f(x) + h(x) - estimate of the\n",
    "\n",
    "*Heuristic is said to be <u>admissible</u>, if it does not overestimate the real value.\n",
    "\n",
    "#### Alogithm (briefly)\n",
    "\n",
    "- OPEN set is a set of communicated nodes\n",
    "- Current Node is a node from OPEN with shortest estimate f\n",
    "- Investigate the neighbors\n",
    "- each admissible cell is transfered to OPEN\n",
    "\n",
    "\n",
    "#### Algorithm (more formally)\n",
    "\n",
    "    function A_Star(start, goal, h)\n",
    "\n",
    "        openSet := {start}\n",
    "        cameFrom := an empty map\n",
    "        gScore := map with default value of Infinity\n",
    "        gScore[start] := 0\n",
    "        fScore := map with default value of Infinity\n",
    "        fScore[start] := h(start)\n",
    "\n",
    "        while openSet is not empty\n",
    "            current := the node in openSet having the lowest fScore[] value\n",
    "            if current = goal\n",
    "                return reconstruct_path(cameFrom, current)\n",
    "\n",
    "            openSet.Remove(current)\n",
    "            for each neighbor of current\n",
    "                tentative_gScore := gScore[current] + d(current, neighbor)\n",
    "                if tentative_gScore < gScore[neighbor]\n",
    "                    cameFrom[neighbor] := current\n",
    "                    gScore[neighbor] := tentative_gScore\n",
    "                    fScore[neighbor] := gScore[neighbor] + h(neighbor)\n",
    "                    if neighbor not in openSet\n",
    "                        openSet.add(neighbor)\n",
    "\n",
    "        return failure\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Relationship to Dikstra algorithm\n",
    "Dikstra's algorithm = find the shortest path in a graph between two points.\n",
    "\n",
    "A* is closely related to Dikstra's algorithm:\n",
    "- A* is an <u>informed</u> variation of Dijkstra algorith - it additionally estimates the remaining path length h(x)\n",
    "- A* is considered a <u>\"best first search\"</u> because it greedily chooses which vertex to explore next based on remaining path estimate.\n",
    "\n",
    "If we make H(x) = const = 0, A* become Disktra's algorithm.\n",
    "\n",
    "__Idea:__ on each step we explore the most promising way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RRT\n",
    "\n",
    "Rapidly Exploring Random Trees\n",
    "\n",
    "It's a purely random way of constructing the space traversing tree\n",
    "\n",
    "Main principles:\n",
    "- New node is generated at a random place\n",
    "    - We encourage exploration => more probability for areas where there is less points\n",
    "- It is connected to the nearest node if:\n",
    "    - there is no obstacle in between,\n",
    "    - new edge is not going to be too long \n",
    "        - MaxDistance = radius in which we generate new points\n",
    "\n",
    "When a new node reaches epsilon neighborhood of the goal => bingo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RRT*\n",
    "\n",
    "RRT* is the same approach as above except one difference: \n",
    "- new node is not necessarily connected to the closest point \n",
    "- rather it is connected to the node that\n",
    "    - maintains tree structure (no loops)\n",
    "    - provides the shorter path to the other node\n",
    "\n",
    "As a number of nodes getting bigger, current shortest path converges to the optimal one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural SLAM\n",
    "\n",
    "[[Benchmarking Classic and Learned Navigation in Complex 3D Environments]](https://arxiv.org/abs/1901.10915)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

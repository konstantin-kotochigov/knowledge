{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "[[Good reference]](https://arxiv.org/pdf/1811.00116.pdf)\n",
    "\n",
    "First of all we should distinguish between the 2 problem settings:\n",
    "- Face Recognition - classify person whose face is on the picture\n",
    "- Face Verification - check whether presented face corresponds to person\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/setting.png\" width=700>\n",
    "\n",
    "Typical process scheme:\n",
    "\n",
    "1. Face detection \n",
    "\n",
    "        find face on the image \n",
    "\n",
    "\n",
    "2. Face alignment \n",
    "\n",
    "        normalize + denoise\n",
    "\n",
    "\n",
    "3. Face description \n",
    "\n",
    "        featurize\n",
    "\n",
    "\n",
    "4. Face recognition \n",
    "\n",
    "        classify\n",
    "\n",
    "#### Problem setting\n",
    "Stating the problem as a multicalss classification (one class for each person) is a bad idea because in general there are very few training examples for each class - we will have to do <u>one-shot learning</u>.\n",
    "\n",
    "It's better to formulate the problem as similarity/distance learning.\n",
    "\n",
    "It could be implemented via siamese network of two CNNs:\n",
    "\n",
    "The standard loss for distance learning is triplet loss.\n",
    "All weights are shared between two branches of the network.\n",
    "\n",
    "### Triplet Loss\n",
    "\n",
    "Triplet Loss uses triplets of data points (anchor, positive, negative). It stems from Metric Learning (Distance Learning) tasks - when we need to construct the optimal distance measure.\n",
    "\n",
    "#### Idea\n",
    "Distance btween similar images must be less than distance between disimilar images:\n",
    "\n",
    "$$d(A,P) < d(A,N)$$\n",
    "\n",
    "The distances are just regular L2 norms\n",
    "\n",
    "- $d(A,P) = ||f(x_A) - f(x_P)||^2$\n",
    "- $d(A,N) = ||f(x_A) - f(x_N)||^2$\n",
    "\n",
    "So the loss function is written as \n",
    "<img src=\"img/triplet_loss.png\" width=500>\n",
    "\n",
    "**NOTE** To avoid situations when model assigns zeros to all points we add some buffer $\\alpha$ into loss function.\n",
    "\n",
    "Альтернативная постановка\n",
    "Можно решать и бинарную задачу.\n",
    "\n",
    "Сконкатенировать выходы сиамской сети, и пустить их в бинарную логистическую регрессию. Здесь y = {0 - люди отличаются, 1 - люди совпадают}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFace\n",
    "\n",
    "[[arxiv]](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf)\n",
    "\n",
    "In 2014 Facebook released article where thay described how face recognition on photos was implemented.\n",
    "\n",
    "Перед тем как пускать регион с лицом на обучение фичей его нормализуют: главным образом поворачивают фронтально. Пердобработка фото выглядит примерно так:\n",
    "\n",
    "<img src=\"img/deepface_preprocessing.png\" width=500>\n",
    "\n",
    "\n",
    "Из статьи не очень понятно, как именно обучалась модель. Но предполагаю что так:\n",
    "1. для обучения весов модели решали задачу k-category classification на некоторой выборке фотографий людей.\n",
    "2. для сравнения с базой строили фичи\n",
    "\n",
    "\n",
    "NOTE\n",
    "здесь они вполне себе решают задачу мультклассификации (one-shot learning)\n",
    "правда датасет большой - 4000 людей по 1000 картинок каждого\n",
    "здесь overfitting на последних слоях как раз неплохо\n",
    "мне кажется supervised обучение нужно только для определения фичей лица, а дальше можно просто ближайших соседей в базе фотографий искать\n",
    "\n",
    "<img src=\"img/deepface_preprocessing2.png\" width=500>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition in pre deep learning era\n",
    "\n",
    "### Gabor Filters\n",
    "\n",
    "Gabor filter = 2D filter, used in CV mainly for detection of regular textures on images. \n",
    "\n",
    "Usually the bunch of such filters are used.\n",
    "\n",
    "Here we can see that Gabor filter in its canonical form is a combnination of (1) gaussian and (2) sinusoid.\n",
    "\n",
    "<img src=\"img/gabor_formula1.png\" width=500>\n",
    "\n",
    "Note that sinusoid here is represented as a complex exponent.\n",
    "\n",
    "Formula parameters:\n",
    "- $\\alpha$ - speed of gaussian decay\n",
    "- $\\gamma$ - ellipsoid-ity of gaussian\n",
    "- $\\lambda$ - sinusoid frequency\n",
    "- $\\psi$ - shift\n",
    "\n",
    "\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Find anchor point of the face, for example center of eyes\n",
    "делается сравнением разных регионов с шаблонной картинкой лица методом template matching (OpenCV)\n",
    "2DNCC = 2d normalized cross-correlation - считается корреляция региона с шаблоном; если f - картинка, а t - шаблон, то:\n",
    "<img src=\"img/gabor_formula_2.png\" width=300>\n",
    "normalized нужно делать потому что яркость может быть разная \n",
    "\n",
    "\n",
    "2. Detect face region\n",
    "\n",
    "\n",
    "3. Normalize it\n",
    "\n",
    "        a. rotate vertically\n",
    "    \n",
    "        b. map this region onto square 64 x 64\n",
    "    \n",
    "        c. average luminance in the region\n",
    "\n",
    "\n",
    "4. Calculate convolutions for 40 gabor filters\n",
    "\n",
    "\n",
    "5. Flatten it into one large vector\n",
    "\n",
    "\n",
    "6. Feature selection using PCA\n",
    "\n",
    "\n",
    "7. Vector compression using LDA\n",
    "\n",
    "\n",
    "8. Classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice \n",
    "\n",
    "https://www.pyimagesearch.com/2018/09/24/opencv-face-recognition/\n",
    "\n",
    "dlib - ML library that contains many functions for face recognition.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

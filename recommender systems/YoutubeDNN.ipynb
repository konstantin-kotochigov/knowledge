{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\n",
    "\n",
    "One of the first papers that presented details on NN approach to recommendations\n",
    "\n",
    "Key innovations:\n",
    "- Two-stage recommendation process: \n",
    "    1. candidate generation (fast but crude) \n",
    "    2. candidate ranking (slow but precise)\n",
    "\n",
    "What benefits does two-stage process provide:\n",
    "- recall - allows efficient navigation through large item space\n",
    "- precision - picks relevant and engaging items for user\n",
    "- blending - allows using using multiple sources\n",
    "\n",
    "<img src=\"img/youtube3.png\" width=500>\n",
    "\n",
    "### Candidate Generation Network\n",
    "Candidate network is a DNN that combines multiple user features into single embedding. \n",
    "\n",
    "*User features are very dynamic since they include history => probably \"query features\" would be a better name\n",
    "\n",
    "This network implements collaborative filering in a sense that it does not rely on content but rely on averaged user watching patterns (those patterns are encoded in embedding space)\n",
    "\n",
    "Model specification\n",
    "- input = user data (user watch history + user query history + user socdem)\n",
    "- pre-output = user embedding\n",
    "- output = softmaxed user embedding multipled by all video vectors\n",
    "- loss function = cross-entropy of the next video prediction\n",
    "\n",
    "<img src=\"img/youtube1.png\" width=750>\n",
    "\n",
    "At training time DNN learns query embeddings in a way that it can easily predict next video by taking dot product with all possible video vectors (see \"softmax => class probabilities\")\n",
    "\n",
    "At inference time DNN performs learned processing and picks top-N most similar videos from a video storage\n",
    "\n",
    "#### Important implementation details\n",
    "\n",
    "- watch vector consists of 50 recent video watches\n",
    "- search vector consists of 50 recent searches\n",
    "- each item and search are encoded with 256 vector embedding\n",
    "- recent searches and watches are not ordered (bag-of-videos / bag-of-searches)\n",
    "- video Vocabulary = 1M video embeddings\n",
    "- search Vocabulary = 1M search string embeddings\n",
    "\n",
    "Negative sampling\n",
    "\n",
    "### Candidate Ranking Network\n",
    "\n",
    "Ranker is a pointwise scoring network trained to predict click probability (optionally weighted by watch time of the click)\n",
    "\n",
    "It uses all user features as well as a lot more video features (as well as user-video interaction features)\n",
    "\n",
    "<img src=\"img/youtube2.png\" width=750>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дайджест работы\n",
    "\n",
    "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\n",
    "\n",
    "Deep Learning драматически улучшил результаты\n",
    "\n",
    "Challenges:\n",
    "- scale\n",
    "- variability\n",
    "- noise (?)\n",
    "\n",
    "Built on rails of Tensorflow, 1B model, 100B training samples\n",
    "\n",
    "До этого DL пытались применять, но не очень часто. Несколько примеров:\n",
    "- AutoRec (2015)<br>вектора рейтингов восстанавливаются обычным автоенкодером\n",
    "- Collaborative DL (2015)<br>комбинируют контентные фичи с рейтингами (зачем-то в генеративной постановке), которые кодируют глубоким автоенкодером\n",
    "- Deep Music (2013)<br>одна из первых контентных систем для музыки\n",
    "\n",
    "\n",
    "### Generation\n",
    "\n",
    "Смотрят только на implicit сигнал, так как его в разы больше\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Задача мультиклассификации на 1M классов (Extreme Multiclass classification)\n",
    "- сэмплирование 1000 негативов\n",
    "- кросс-энтропия?\n",
    "- пробовали еще иерархический софтмакс, но не залетел\n",
    "\n",
    "Кандидаты отбираются с помощью ANN для поиска соседей. Метод не описывается (что-то с хэшированием), но отмечается, что выбор конкретной модели сильно не влияет на качество\n",
    "\n",
    "В качестве фичи добавляют возраст видео (example age), так как считается, что \"свежесть\" контента влияет на потребление\n",
    "\n",
    "### Ranking\n",
    "\n",
    "что делает = оценивает каждого кандидата на показ из набранного пула с точки зрения, насколько подходит пользователю\n",
    "\n",
    "чем полезен:\n",
    "- мало кандидатов => можно точнее персонализировать\n",
    "- часто рекомендации из разных источников несравнимы => ранжирует уже финальный список\n",
    "\n",
    "целевая фунцкия = оптимизируется под E[watch_time] (у отсутствия клика его считаем отрицательным)<br>\n",
    "*Можно и под CTR, но он подвержен кликбейтовости\n",
    "\n",
    "фичей много (несколько сотен). Среди них есть:\n",
    "- категориальные / непрерывные\n",
    "- бинарные (факт залогина) / высококардинальные (последний запрос)\n",
    "- univalent / multivalent (список просмотров)\n",
    "\n",
    "по типу:\n",
    "- impression features = фичи оцениваемого видео\n",
    "- query features = фичи user + context<br>считается только раз на запрос\n",
    "- user-video interaction features = отношение с пользователем <br>например, similar videos rating, topic, channel<br>важны, так как\n",
    "    - легче обобщать пользовательские предпочтения\n",
    "    - допускают 'затухание' неинтересных рекомендаций\n",
    "\n",
    "детали:\n",
    "- категориальные фичи кодируются словарями эмбедингов<br>если значений много, оставляют только некий фиксированный топ\n",
    "- если фича входит несоклько раз, словарь используется один <br>shared embedding\n",
    "- непрерывные фичи нормализуются до интревала [0,1]\n",
    "- источник рекомендации и скор тоже важные фичи на этапе ранжирования\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

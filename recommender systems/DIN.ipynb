{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Interest Network (2018)\n",
    "\n",
    "https://arxiv.org/pdf/1706.06978\n",
    "\n",
    "In 2018 Alibaba inspired by Youtube paper suggested its own way to solve ad CTR prediction task. \n",
    "\n",
    "CTR prediction is not a recommendation task but setting very similar to ranking part of YoutubeDNN - score using previous user behavior\n",
    "\n",
    "This architecture is called DIN (Deep Interest Network)\n",
    "\n",
    "Key ideas\n",
    "- add local activation unit - attention-like mechanism that would assign weight to each recent user action depending on current candidate that is being scored\n",
    "- enhance item embeddings by encoding categorical features along with item IDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference architecture\n",
    "\n",
    "Base architecture that they've had before is almost identical to one of Youtube (Ranking Network) with only few changes:\n",
    "- augmented user embeddings\n",
    "- pReLU activation function instead of ReLU\n",
    "- sum pooling instead of average\n",
    "\n",
    "<img src=\"img/deepinterest1.png\" width=500>\n",
    "\n",
    "### Augmented item embeddings\n",
    "Combine item embeddings with categorical embeddings. \n",
    "\n",
    "They use three embeddings for each item (see them on scheme):\n",
    "- trainable item embedding\n",
    "- vendor embedding\n",
    "- category embedding\n",
    "\n",
    "After quering dictionary they are concatenated in one embedding\n",
    "\n",
    "### pReLu activation function\n",
    "\n",
    "<img src=\"img/relu.png\" width=150><img src=\"img/prelu.png\" width=150>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New architecture\n",
    "\n",
    "They proposed several of enhancments:\n",
    "- add attention-like mechanism (they call it activation unit)\n",
    "- use Dice activation function\n",
    "- mini-batch regularization\n",
    "\n",
    "<img src=\"img/deepinterest2.png\" width=750>\n",
    "\n",
    "### 1. Local activation\n",
    "They added activation unit to each item in user history. For each item in user history it scores its relevance to candidate item and scales its embedding according to this score\n",
    "\n",
    "Local activation = \"activation\" of user interest under particular circumstances\n",
    "It's not self-attention since does not require normalization, but is very simlar approach\n",
    "\n",
    "<img src=\"img/activation.png\" width=750>\n",
    "\n",
    "### 2. Data-adaptive activation function\n",
    "\n",
    "Previously used pReLU is partially linear activation with 1 parameter (line angle for negative X)\n",
    "<img src=\"img/prelu.png\" width=150>\n",
    "\n",
    "They made inflection point also trainable and smooth and called this activation \"Dice\"\n",
    "\n",
    "<img src=\"img/dice_formula.png\" width=300>\n",
    "\n",
    "Control function (where mode is changed) is now like this\n",
    "\n",
    "<img src=\"img/dice.png\" width=300>\n",
    "\n",
    "### 3. Regularization\n",
    "\n",
    "Multipart embeddings require regularization. Here is a good illustration why (green line = no regularization)\n",
    "<img src=\"img/reg_dynamic.png\" width=900>\n",
    "\n",
    "Note that we separately regularize each dictionary, not whole network at once\n",
    "\n",
    "__Tried regularization methods__\n",
    "- Dropout<br> Randomly discard 50% of feature ids in each\n",
    "sample<br><br>\n",
    "- Filter<br>leave only the most frequent items (top 20 million)<br><br>\n",
    "- DiFacto<br>regularize frequent features less<br><br>\n",
    "- new Mini-Batch Aware regularization method (Î» = 0.01)<br><br>\n",
    "\n",
    "#### Mini-Batch Aware regularization\n",
    "MBA = sampled regularization. \n",
    "\n",
    "\n",
    "Let $W$ be dictionary weights for some categorical feature, $K$ - embedding size. Then sum all matrix weights\n",
    "\n",
    "<img src=\"img/reg_mba1.png\" width=350>\n",
    "\n",
    "If we split this in $B$ batches:\n",
    "<img src=\"img/reg_mba2.png\" width=300>\n",
    "\n",
    "\n",
    "If $\\alpha_{jm}$ denotes that feature value $j$ is present at least in one example of this particular batch $m$ then\n",
    "\n",
    "<img src=\"img/reg_mba3.png\" width=200>\n",
    "\n",
    "<img src=\"img/minibatch_reg.png\" width=350>\n",
    "\n",
    "Comparison of different regularization methods:\n",
    "\n",
    "<img src=\"img/reg.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## Datasets\n",
    "\n",
    "They tested their approach on 3 datasets (2 open and one private)\n",
    "- Amazon - item reviews\n",
    "- MovieLens - movie ratings\n",
    "- Alibaba - ad serving logs\n",
    "\n",
    "They had to adapt Amazon and MovieLens to completely different task to mimic CTR prediction. No idea how they did it\n",
    "- Amazon = predict next review based on current reviews\n",
    "- MovieLens = predict \"good\" rating based on previous ratings\n",
    "\n",
    "<img src=\"img/datasets.png\" width=500>\n",
    "\n",
    "## Metrics\n",
    "\n",
    "They used two main metrics:\n",
    "- weighted AUC<br>AUC = how good predicted CTR-score divides two classes<br>weighted AUC = AUC weighted by user activity<br><img src=\"img/weighted_auc.png\" width=200>\n",
    "- Relative AUC<br>uplift to baseline (Youtube) model on AUC normalized scale<br><img src=\"img/relauc.png\" width=350>\n",
    "\n",
    "\n",
    "\n",
    "## Model comparison\n",
    "\n",
    "Alternative models\n",
    "- Logistic Regression\n",
    "- BaseModel = Youtube like NN\n",
    "- Wide'n'Deep<br>SOTA architecture that combines memorization (one-hot encoded feature interactions) / generalization network (embeddings followed by MLP)\n",
    "- PNN <br>Product neural network\n",
    "- DeepFM<br>combination of FM features and MLP proccessing\n",
    "\n",
    "Evaluation on open datasets\n",
    "\n",
    "<img src=\"img/models2.png\" width=500>\n",
    "\n",
    "Evaluation on private datasets\n",
    "\n",
    "<img src=\"img/models1.png\" width=500>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

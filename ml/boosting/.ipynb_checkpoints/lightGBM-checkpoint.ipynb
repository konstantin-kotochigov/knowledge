{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2016, Microsoft implementation of GBM\n",
    "\n",
    "[[paper]](https://papers.nips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)\n",
    "\n",
    "\n",
    "#### Key ideas:\n",
    "\n",
    "- Histogram based split finding\n",
    "\n",
    "    it's not a new idea, it was well-known before (for example, when constructing decision trees), but since it's more effective then pre-sorted split find, they make a big use of it\n",
    "\n",
    "\n",
    "- GOSS (Gradient-based one side sampling) \n",
    "    \n",
    "    during the model update process it's more sensible to give more attention to under-trained examples (cases with high loss gradient), examples with low gradient can be safely be undersampled. This accelerates the training process significantly.\n",
    "\n",
    "\n",
    "- EFB (Exclusive Feature Bundling)\n",
    "\n",
    "    features that are frequently mutually exclusive can be combined into one feature. In the setting of highly sparse data this reduces algorithm complexity significantly.\n",
    "\n",
    "All other innovations has to do with efficient and convenient implementation, not algorithm.\n",
    "\n",
    "\n",
    "#### How exactly does GOSS work\n",
    "\n",
    "On each step they:\n",
    "1. select $\\alpha$ examples with the largest loss function values (largest deviance) and then \n",
    "2. randomly sample $\\beta$ examples from all other cases\n",
    "\n",
    "#### How exactly does EFB work\n",
    "\n",
    "They create incidence graph between features and try ro colorize that graph into exclusive sets of features.\n",
    "\n",
    "#### How categorical features are tackled\n",
    "\n",
    "They claim that one-hot encoding is inefficient. Instead they \n",
    "1. compute categorical histogram with averaged gradients for each category\n",
    "2. find the best combination of categories in 2 sets according (they always do binary splits)\n",
    "\n",
    "Available algorithms:\n",
    "- GBDT - standard approach\n",
    "- DART - boosting with dropouts\n",
    "- GOSS - sampled training\n",
    "- RF - they added it just for completeness (?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "Key class for storing data is called **lgb.Dataset**\n",
    "\n",
    "API is pretty much the same as in XGBoost.\n",
    "\n",
    "<img src=\"img/lightgbm_datatset.png\" width=350>\n",
    "\n",
    "Available data sources:\n",
    "- Pandas dataframe\n",
    "- numpy ndarray\n",
    "- scipy sparse matrix\n",
    "- CSV, TXT, LibSVM files\n",
    "- binary lightGBM files\n",
    "\n",
    "Differences with XGB:\n",
    "- class is called Dataset instead of DMatrix\n",
    "- you can also load from TXT\n",
    "- there is a support for categorical features - one must define them explicitly\n",
    "\n",
    "#### Type reuiqerments\n",
    "All features must be int, float or bool. Strings must be converted to numeric types.\n",
    "\n",
    "There is more flexibility with parameters:\n",
    "- two_round_loading\n",
    "- enable_feature_bundling\n",
    "- bucketing strategy:\n",
    "  - max_bin\n",
    "  - min_bin\n",
    "  - bin_sample_cnt\n",
    "- free_raw_data\n",
    "\n",
    "Dataset is a <u>link</u> to data. It does not do loading when defined. First loading is occured during train process.\n",
    "\n",
    "Setting **free_raw_data** to False is mandatory when using categortical features. Otherwise you could only call train() once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall schema\n",
    "\n",
    "<img src=\"img/lightgbm.png\" width=750>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-152ee4070064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_raw_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_raw_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# train_data = lgb.Dataset(X, label=y, free_raw_data=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lgb' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_kddcup99\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "X,y = fetch_kddcup99(return_X_y = True)\n",
    "\n",
    "feature_names = [\"feature_\"+str(x) for x in range(X.shape[1])]\n",
    "exclude_features = ['feature_1','feature_2','feature_3']\n",
    "\n",
    "X = pd.DataFrame(X, columns=feature_names, dtype=None)\n",
    "X = X[X.columns.difference(exclude_features)].astype(np.float)\n",
    "\n",
    "y = np.random.choice([0,1], X.shape[0])\n",
    "\n",
    "categorical_features = ['feature_11','feature_13','feature_14','feature_6','feature_7','feature_8']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features, free_raw_data=False)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=categorical_features, free_raw_data=False, reference=train_data)\n",
    "# train_data = lgb.Dataset(X, label=y, free_raw_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters\n",
    "\n",
    "[[nice tutorial on LGB parameters]](https://neptune.ai/blog/lightgbm-parameters-guide)\n",
    "\n",
    "In lightGBM all parameters are global. \n",
    "\n",
    "There are several ways you can set them up:\n",
    "- in config file\n",
    "- using param dicionary\n",
    "- in particular classes or methods\n",
    "\n",
    "The are 100+ parameters.\n",
    "- core params = objective and evaluation metrics / algorithm\n",
    "- training params = n_estimators / learning_rate\n",
    "- base learner params = max_depth / max_leaves\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no different models for different tasks like in scikit-learn (LGBMCLassifier, LGBMRegressor).\n",
    "\n",
    "The type of task is defined only by its objective:\n",
    "- MSE + L2 for regression tasks\n",
    "- binary / multiclass for classification tasks\n",
    "- lambdarank for ranking tasks\n",
    "\n",
    "Implemented bossting types:\n",
    "- GBT\n",
    "- DART\n",
    "- GOSS\n",
    "- RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimal Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.train(\n",
    "    train_set = train_data, \n",
    "    params = {'objective':'binary'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to track training process using evaluation metrics\n",
    "\n",
    "- Parameter **valid_sets** defines datasets on which evaluation will be done (including training data if necessary)\n",
    "- Parameter __feval__ defines metrics\n",
    "- Parameter __valid_names__ defines datasets names in evaluation results\n",
    "\n",
    "You should manually provide dictionary where the evaluation results will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "lgb.train(\n",
    "    train_data,\n",
    "    valid_sets = [train_data, valid_data],\n",
    "    feval = ['auc','logloss'],\n",
    "    valid_names = ['super_train_data','super_valid_data'], \n",
    "    evals_result = results_dict)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(results_dict['train']['auc'], label='train', color='red')\n",
    "plt.plot(results_dict['valid']['auc'], label='valid', color='green')\n",
    "plt.grid(True, linestyle='dotted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To suppress printing each iteration:\n",
    "`verbose_eval=False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use early stopping\n",
    "\n",
    "`lgb.train(early_stopping_rounds = 10)`\n",
    "\n",
    "or \n",
    "\n",
    "`params['early_stopping_rounds']=10`\n",
    "\n",
    "will stop training if there is no improvement in validation score.\n",
    "\n",
    "- It checks only **validation** sets\n",
    "\n",
    "    there must be at least one validation set (with a reference) defined in valid_sets\n",
    "\n",
    "\n",
    "- It checks **all** metrics\n",
    "    \n",
    "    you could enforce it to check only the first metric (for example ROC_AUC) by setting **first_metric_only** parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed training\n",
    "\n",
    "params['tree_learner'] = \n",
    "- serial\n",
    "- feature parallel\n",
    "- data parallel\n",
    "- voting\n",
    "\n",
    "params['device_type'] = \n",
    "- cpu\n",
    "- gpu\n",
    "- cuda\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation (Sklearn)\n",
    "\n",
    "There is a number of wrappers for scikit-learn. They make it possible to plug LGBM models into standard scikit-learn pipelines:\n",
    "- LGBMClassifier()\n",
    "- LGBMRegressor()\n",
    "- LGBMRanker()\n",
    "\n",
    "They differ only with default objective function. Ensemble algorithm is the same.\n",
    "\n",
    "For example, they provide standard __n_estimators__ parameter instead of __num_rounds_count__.\n",
    "\n",
    "boosting_type =\n",
    "- lgbt\n",
    "- dart\n",
    "- goss\n",
    "- random forest\n",
    "\n",
    "importance_type = \n",
    "- split - number of times feature is used in splits\n",
    "- gain - total gain achieved by splitting this feature\n",
    "\n",
    "To train and apply model use fit() and predict() correspondingly.\n",
    "\n",
    "You can still set most of the parameters using kwargs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
